{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 온라인 선호지수 도출하는 함수\n",
    "\n",
    "#### [달라지는 변수]\n",
    "#### 1)sampling 개수 from customer segmetation : 10000명, 20000명\n",
    "#### 2)distance 종류 : cosine, euclidean\n",
    "#### 3)kmeans clustering 적용 or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def get_mse(pred,actual):\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    \n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 구매선호지수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 10000명 sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: {:4.2f}% 13.162443018558125\n",
      "(5029, 37)\n",
      "(2477, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기 및 초기화\n",
    "Purchase_Count = pd.read_csv(\"C:/Users/lsh93/Desktop/Lpoint/data2/Purchase_Count.csv\")\n",
    "Purchase_Count = Purchase_Count.rename(columns = {'Unnamed: 0':'CLNT_ID'})\n",
    "clustered_10000 = pd.read_csv(\"C:/Users/lsh93/Desktop/Lpoint/output2/clustered_10000.csv\", encoding = \"UTF-8\")\n",
    "clustered_10000 = clustered_10000.drop(['Unnamed: 0'], axis = 1)\n",
    "Purchase_Count = pd.merge(Purchase_Count, clustered_10000[['CLNT_ID']], how = 'inner', on ='CLNT_ID')\n",
    "row_names = Purchase_Count['CLNT_ID'].as_matrix()\n",
    "col_names = Purchase_Count.columns.values\n",
    "col_names = col_names[1:]\n",
    "PC = Purchase_Count.as_matrix()\n",
    "PC = PC[:,1:]\n",
    "Purchase_Count = pd.DataFrame(PC, columns = col_names, index = row_names)\n",
    "#sparsity구하기\n",
    "sparsity = float(len(PC.nonzero()[0]))\n",
    "sparsity /= (PC.shape[0] * PC.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.2f}%',format(sparsity))\n",
    "#test set과 training set으로 나누기\n",
    "PC_train, PC_test = train_test_split(Purchase_Count, test_size = 0.33, random_state = 50)\n",
    "print(PC_train.shape)\n",
    "print(PC_test.shape)\n",
    "PC_train = pd.DataFrame(PC_train)\n",
    "PC_test = pd.DataFrame(PC_test)\n",
    "#array 형태로 변환\n",
    "train_mat = PC_train.as_matrix()\n",
    "test_mat = PC_test.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 20000명 sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: {:4.2f}% 14.349619166222743\n",
      "(10265, 37)\n",
      "(5057, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기 및 초기화\n",
    "Purchase_Count = pd.read_csv(\"C:/Users/lsh93/Desktop/Lpoint/data2/Purchase_Count.csv\")\n",
    "Purchase_Count = Purchase_Count.rename(columns = {'Unnamed: 0':'CLNT_ID'})\n",
    "clustered_10000 = pd.read_csv(\"C:/Users/lsh93/Desktop/Lpoint/output2/clustered_20000.csv\", encoding = \"UTF-8\")\n",
    "clustered_10000 = clustered_10000.drop(['Unnamed: 0'], axis = 1)\n",
    "Purchase_Count = pd.merge(Purchase_Count, clustered_10000[['CLNT_ID']], how = 'inner', on ='CLNT_ID')\n",
    "row_names = Purchase_Count['CLNT_ID'].as_matrix()\n",
    "col_names = Purchase_Count.columns.values\n",
    "col_names = col_names[1:]\n",
    "PC = Purchase_Count.as_matrix()\n",
    "PC = PC[:,1:]\n",
    "Purchase_Count = pd.DataFrame(PC, columns = col_names, index = row_names)\n",
    "#sparsity구하기\n",
    "sparsity = float(len(PC.nonzero()[0]))\n",
    "sparsity /= (PC.shape[0] * PC.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.2f}%',format(sparsity))\n",
    "#test set과 training set으로 나누기\n",
    "PC_train, PC_test = train_test_split(Purchase_Count, test_size = 0.33, random_state = 50)\n",
    "print(PC_train.shape)\n",
    "print(PC_test.shape)\n",
    "PC_train = pd.DataFrame(PC_train)\n",
    "PC_test = pd.DataFrame(PC_test)\n",
    "#array 형태로 변환\n",
    "train_mat = PC_train.as_matrix()\n",
    "test_mat = PC_test.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구매선호지수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "###파라메터 = k랑 코사인 \n",
    "def purchase_prediction(train_mat, test_mat, metric_, k, output = False, scaling = False):\n",
    "    if scaling == True:\n",
    "        train_mat = (train_mat.T/train_mat.sum(axis=1)).T\n",
    "        test_mat = (test_mat.T/test_mat.sum(axis=1)).T\n",
    "    \n",
    "    dist_out = 1 - pairwise_distances(train_mat, metric= metric_)\n",
    "\n",
    "    #without kmeans clustering\n",
    "    user_pred = dist_out.dot(train_mat)/np.array([np.abs(dist_out).sum(axis = 1)]).T\n",
    "    print('w/o kmeans, train:  ',get_mse(user_pred, train_mat))\n",
    "    print('w/o kmeans, test:  ',get_mse(user_pred, test_mat))\n",
    "\n",
    "    #with kmeans clustering\n",
    "    neigh = NearestNeighbors(k, metric_)\n",
    "    neigh.fit(train_mat)\n",
    "    top_k_distances, top_k_users = neigh.kneighbors(train_mat, return_distance = True)\n",
    "    user_pred_k = np.zeros(train_mat.shape)\n",
    "    \n",
    "    for i in range(PC_train.shape[0]):\n",
    "        user_pred_k[i,:] = top_k_distances[i].T.dot(train_mat[top_k_users][i]) / np.array([np.abs(top_k_distances[i].T).sum(axis = 0)]).T  \n",
    "    online_pref = pd.DataFrame(user_pred_k)\n",
    "    na_element_index = np.where(np.isnan(online_pref))\n",
    "    na_row_index = np.unique(na_element_index[0])\n",
    "    removed_CLNT_ID = PC_train.index.values[na_row_index]\n",
    "    existed_CLNT_ID = np.delete(PC_train.index.values,na_row_index)\n",
    "    online_pref2 = online_pref.dropna()\n",
    "    user_pred_k2 = online_pref2.as_matrix()\n",
    "    train_mat2 = train_mat\n",
    "    exist_idx = np.delete([range(online_pref.shape[0])],na_row_index)\n",
    "    train_mat2 = train_mat2[exist_idx,:]\n",
    "    print('w/ kmeans, train:  ',get_mse(user_pred_k2, train_mat2))\n",
    "    print('w/ kmeans, test:  ',get_mse(user_pred_k2, test_mat))\n",
    "\n",
    "    #kmeans 적용한 선호지수 matrix 생성\n",
    "    if output == True :\n",
    "        col_names = Purchase_Count.columns.values\n",
    "        row_names = existed_CLNT_ID\n",
    "        Online_Preference_Count = pd.DataFrame(user_pred_k2, columns = col_names, index = row_names)\n",
    "        return Online_Preference_Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10000명 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   86.29608098337549\n",
      "w/o kmeans, test:   96.9784070077395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   28.63931852286754\n",
      "w/ kmeans, test:   119.46998898239328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#10000명 sampling한 경우, cosine distance 쓴 경우, k = 5\n",
    "opc = purchase_prediction(train_mat,test_mat, \"cosine\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   182.66721252039383\n",
      "w/o kmeans, test:   204.19730497273184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   28.63931852286754\n",
      "w/ kmeans, test:   119.46998898239328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#10000명 sampling한 경우, euclidean distance 쓴 경우, k = 5\n",
    "opc = purchase_prediction(train_mat,test_mat, \"euclidean\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   85.40834048933255\n",
      "w/o kmeans, test:   99.37528162986564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   28.63931852286754\n",
      "w/ kmeans, test:   119.46998898239328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#10000명 sampling한 경우, correlation 쓴 경우, k = 5\n",
    "opc = purchase_prediction(train_mat,test_mat, \"correlation\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   0.028131755848825844\n",
      "w/o kmeans, test:   0.06975756911905921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.002720327647331267\n",
      "w/ kmeans, test:   0.08571259018474586\n",
      "w/o kmeans, train:   0.04161443327691153\n",
      "w/o kmeans, test:   0.08295957767369831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.002720327647331267\n",
      "w/ kmeans, test:   0.08571259018474586\n",
      "w/o kmeans, train:   0.028816220429387387\n",
      "w/o kmeans, test:   0.07564184275249344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.002720327647331267\n",
      "w/ kmeans, test:   0.08571259018474586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "##Scaling 적용할 경우\n",
    "#10000명 sampling한 경우, cosine distance 쓴 경우, k = 5\n",
    "opc = purchase_prediction(train_mat,test_mat, \"cosine\", 5, True, True)\n",
    "opc = purchase_prediction(train_mat,test_mat, \"euclidean\", 5, True, True)\n",
    "opc = purchase_prediction(train_mat,test_mat, \"correlation\", 5, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20000명 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   408.05193415503004\n",
      "w/o kmeans, test:   587.0903686780509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   92.52537404004526\n",
      "w/ kmeans, test:   611.035951966975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#20000명 sampling한 경우, cosine distance 쓴 경우, k = 5\n",
    "opc = purchase_prediction(train_mat,test_mat, \"cosine\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   754.4943007098875\n",
      "w/o kmeans, test:   880.4058472057757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   92.52537404004526\n",
      "w/ kmeans, test:   611.035951966975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#20000명 sampling한 경우, euclidean distance 쓴 경우, k = 5\n",
    "opc = purchase_prediction(train_mat,test_mat, \"euclidean\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   551.052167205421\n",
      "w/o kmeans, test:   592.0709278543959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   92.52537404004526\n",
      "w/ kmeans, test:   611.035951966975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#20000명 sampling한 경우, correlation 쓴 경우, k = 5\n",
    "opc = purchase_prediction(train_mat,test_mat, \"correlation\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   0.02787429540003764\n",
      "w/o kmeans, test:   0.0633956288578198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.0021484541788169575\n",
      "w/ kmeans, test:   0.07772765830475424\n",
      "w/o kmeans, train:   0.04411056198193033\n",
      "w/o kmeans, test:   0.07349003954176009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.0021484541788169575\n",
      "w/ kmeans, test:   0.07772765830475424\n",
      "w/o kmeans, train:   0.03017625696720918\n",
      "w/o kmeans, test:   0.06956324211410529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.0021484541788169575\n",
      "w/ kmeans, test:   0.07772765830475424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>스포츠패션</th>\n",
       "      <th>남성의류</th>\n",
       "      <th>유아동의류</th>\n",
       "      <th>청소/세탁/욕실용품</th>\n",
       "      <th>완구</th>\n",
       "      <th>패션잡화</th>\n",
       "      <th>시즌스포츠</th>\n",
       "      <th>여성의류</th>\n",
       "      <th>인테리어/조명</th>\n",
       "      <th>속옷/양말/홈웨어</th>\n",
       "      <th>...</th>\n",
       "      <th>음료</th>\n",
       "      <th>구기/필드스포츠</th>\n",
       "      <th>냉장/세탁가전</th>\n",
       "      <th>냉동식품</th>\n",
       "      <th>냉장식품</th>\n",
       "      <th>원예/애완</th>\n",
       "      <th>상품권</th>\n",
       "      <th>자동차용품</th>\n",
       "      <th>축산물</th>\n",
       "      <th>영상/음향가전</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6382771</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456508</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5888892</th>\n",
       "      <td>0.072825</td>\n",
       "      <td>0.024841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033262</td>\n",
       "      <td>0.016550</td>\n",
       "      <td>0.806235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399944</th>\n",
       "      <td>0.883867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793121</th>\n",
       "      <td>0.058681</td>\n",
       "      <td>0.067825</td>\n",
       "      <td>0.519429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.251477</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840339</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161500</th>\n",
       "      <td>0.052976</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>0.081058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94099</th>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027454</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.039766</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893690</th>\n",
       "      <td>0.020571</td>\n",
       "      <td>0.024339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845631</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911038</th>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630293</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080920</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>0.283707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195232</th>\n",
       "      <td>0.091260</td>\n",
       "      <td>0.076703</td>\n",
       "      <td>0.117468</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.035917</td>\n",
       "      <td>0.091417</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281801</th>\n",
       "      <td>0.042855</td>\n",
       "      <td>0.105788</td>\n",
       "      <td>0.060673</td>\n",
       "      <td>0.014761</td>\n",
       "      <td>0.146084</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872046</th>\n",
       "      <td>0.050094</td>\n",
       "      <td>0.035591</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030637</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.083355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391964</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420720</th>\n",
       "      <td>0.012708</td>\n",
       "      <td>0.087601</td>\n",
       "      <td>0.246338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007785</td>\n",
       "      <td>0.343341</td>\n",
       "      <td>0.055429</td>\n",
       "      <td>0.096529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784391</th>\n",
       "      <td>0.011288</td>\n",
       "      <td>0.267805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.647853</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273632</th>\n",
       "      <td>0.054405</td>\n",
       "      <td>0.206003</td>\n",
       "      <td>0.186551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126406</td>\n",
       "      <td>0.035439</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780855</th>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.024183</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.014059</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.027178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329199</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947160</th>\n",
       "      <td>0.035835</td>\n",
       "      <td>0.306350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075199</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>0.100725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075700</th>\n",
       "      <td>0.782164</td>\n",
       "      <td>0.217836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811724</th>\n",
       "      <td>0.069982</td>\n",
       "      <td>0.056389</td>\n",
       "      <td>0.220201</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.050686</td>\n",
       "      <td>0.109201</td>\n",
       "      <td>0.041304</td>\n",
       "      <td>0.092212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891232</th>\n",
       "      <td>0.061168</td>\n",
       "      <td>0.077170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061215</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.494199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798018</th>\n",
       "      <td>0.042748</td>\n",
       "      <td>0.125697</td>\n",
       "      <td>0.315961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009779</td>\n",
       "      <td>0.047356</td>\n",
       "      <td>0.028590</td>\n",
       "      <td>0.137101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758423</th>\n",
       "      <td>0.029359</td>\n",
       "      <td>0.042841</td>\n",
       "      <td>0.141007</td>\n",
       "      <td>0.194514</td>\n",
       "      <td>0.034334</td>\n",
       "      <td>0.043844</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.038139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819226</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6006194</th>\n",
       "      <td>0.007730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024158</td>\n",
       "      <td>0.343016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546518</th>\n",
       "      <td>0.133530</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420494</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.367204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6247353</th>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431483</th>\n",
       "      <td>0.046946</td>\n",
       "      <td>0.099675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055523</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.097413</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.296460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832211</th>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072717</td>\n",
       "      <td>0.030682</td>\n",
       "      <td>0.024584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119542</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324487</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5662235</th>\n",
       "      <td>0.031723</td>\n",
       "      <td>0.015439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021673</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.035646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169344</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.706307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5136367</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232509</th>\n",
       "      <td>0.039865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199979</td>\n",
       "      <td>0.137712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822519</th>\n",
       "      <td>0.160938</td>\n",
       "      <td>0.159508</td>\n",
       "      <td>0.118143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>0.052378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562567</th>\n",
       "      <td>0.421393</td>\n",
       "      <td>0.133498</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511277</th>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.035233</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.011648</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.135383</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.042349</td>\n",
       "      <td>0.319080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519443</th>\n",
       "      <td>0.082383</td>\n",
       "      <td>0.135408</td>\n",
       "      <td>0.048109</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.026170</td>\n",
       "      <td>0.081501</td>\n",
       "      <td>0.118632</td>\n",
       "      <td>0.091760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015891</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710923</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116194</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411997</td>\n",
       "      <td>0.028029</td>\n",
       "      <td>0.241589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65319</th>\n",
       "      <td>0.073601</td>\n",
       "      <td>0.043213</td>\n",
       "      <td>0.024181</td>\n",
       "      <td>0.008741</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>0.069183</td>\n",
       "      <td>0.017406</td>\n",
       "      <td>0.048927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020013</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010004</th>\n",
       "      <td>0.286840</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.304842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.333417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904892</th>\n",
       "      <td>0.057306</td>\n",
       "      <td>0.417133</td>\n",
       "      <td>0.039897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279122</td>\n",
       "      <td>0.022170</td>\n",
       "      <td>0.102783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809157</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807076</th>\n",
       "      <td>0.080663</td>\n",
       "      <td>0.038353</td>\n",
       "      <td>0.138880</td>\n",
       "      <td>0.019147</td>\n",
       "      <td>0.011558</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>0.200096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227884</th>\n",
       "      <td>0.304475</td>\n",
       "      <td>0.294645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324912</th>\n",
       "      <td>0.015730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918792</th>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.006060</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842428</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279819</th>\n",
       "      <td>0.030443</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.036725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015842</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.783928</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058165</th>\n",
       "      <td>0.064279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591500</th>\n",
       "      <td>0.282501</td>\n",
       "      <td>0.043323</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043323</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.530007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640113</th>\n",
       "      <td>0.072551</td>\n",
       "      <td>0.024160</td>\n",
       "      <td>0.345951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082048</td>\n",
       "      <td>0.021869</td>\n",
       "      <td>0.032658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5410862</th>\n",
       "      <td>0.074592</td>\n",
       "      <td>0.014797</td>\n",
       "      <td>0.479465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.029506</td>\n",
       "      <td>0.022146</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673582</th>\n",
       "      <td>0.059439</td>\n",
       "      <td>0.058418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.107653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055838</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>0.102157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802236</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            스포츠패션      남성의류     유아동의류  청소/세탁/욕실용품        완구      패션잡화  \\\n",
       "6382771  0.000000  0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "456508   0.777778  0.222222  0.000000    0.000000  0.000000  0.000000   \n",
       "5888892  0.072825  0.024841  0.000000    0.000000  0.000000  0.033262   \n",
       "3399944  0.883867  0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "5793121  0.058681  0.067825  0.519429    0.000000  0.000000  0.085000   \n",
       "840339   0.000000  0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "2161500  0.052976  0.432836  0.000000    0.000000  0.000000  0.045757   \n",
       "4257175  0.000000  0.000000  0.000000    0.000000  0.015971  0.081058   \n",
       "94099    0.001848  0.003695  0.000000    0.027454  0.001848  0.039766   \n",
       "2893690  0.020571  0.024339  0.000000    0.000000  0.000000  0.016803   \n",
       "845631   0.000000  0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "3911038  0.021469  0.005367  0.000000    0.000000  0.000000  0.005367   \n",
       "2630293  0.000000  0.135686  0.000000    0.000000  0.000000  0.080920   \n",
       "1195232  0.091260  0.076703  0.117468    0.004433  0.035917  0.091417   \n",
       "4281801  0.042855  0.105788  0.060673    0.014761  0.146084  0.038986   \n",
       "872046   0.050094  0.035591  0.002844    0.010340  0.000000  0.030637   \n",
       "4420720  0.012708  0.087601  0.246338    0.000000  0.007785  0.343341   \n",
       "1784391  0.011288  0.267805  0.000000    0.000000  0.000000  0.027900   \n",
       "6273632  0.054405  0.206003  0.186551    0.000000  0.000000  0.126406   \n",
       "780855   0.001503  0.024183  0.001260    0.017341  0.001260  0.014059   \n",
       "508      0.027178  0.000000  0.000000    0.000000  0.000000  0.329199   \n",
       "4947160  0.035835  0.306350  0.000000    0.000000  0.000000  0.075199   \n",
       "1075700  0.782164  0.217836  0.000000    0.000000  0.000000  0.000000   \n",
       "2811724  0.069982  0.056389  0.220201    0.011321  0.050686  0.109201   \n",
       "1891232  0.061168  0.077170  0.000000    0.010107  0.000000  0.061215   \n",
       "4798018  0.042748  0.125697  0.315961    0.000000  0.009779  0.047356   \n",
       "3758423  0.029359  0.042841  0.141007    0.194514  0.034334  0.043844   \n",
       "819226   0.000000  0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "6006194  0.007730  0.000000  0.024158    0.343016  0.000000  0.052007   \n",
       "3546518  0.133530  0.037200  0.000000    0.000000  0.000000  0.420494   \n",
       "...           ...       ...       ...         ...       ...       ...   \n",
       "6247353  0.010951  0.000000  0.000000    0.000000  0.000000  0.010951   \n",
       "5431483  0.046946  0.099675  0.000000    0.014881  0.000000  0.055523   \n",
       "5832211  0.012783  0.000000  0.012783    0.000000  0.000000  0.072717   \n",
       "1119542  0.000000  0.324487  0.004533    0.000000  0.000000  0.037651   \n",
       "5662235  0.031723  0.015439  0.000000    0.679332  0.000000  0.021673   \n",
       "2169344  0.000000  0.706307  0.000000    0.000000  0.000000  0.215238   \n",
       "5136367  0.000000  0.284762  0.000000    0.000000  0.000000  0.010184   \n",
       "2232509  0.039865  0.000000  0.600041    0.000000  0.000000  0.199979   \n",
       "3822519  0.160938  0.159508  0.118143    0.000000  0.013940  0.052378   \n",
       "6562567  0.421393  0.133498  0.015017    0.000000  0.000000  0.234900   \n",
       "2511277  0.006411  0.035233  0.003883    0.011648  0.003883  0.135383   \n",
       "2519443  0.082383  0.135408  0.048109    0.003259  0.026170  0.081501   \n",
       "5710923  0.842105  0.000000  0.000000    0.000000  0.000000  0.157895   \n",
       "5116194  0.000000  0.043153  0.000000    0.000000  0.000000  0.411997   \n",
       "65319    0.073601  0.043213  0.024181    0.008741  0.002582  0.069183   \n",
       "1010004  0.286840  0.025806  0.304842    0.000000  0.000000  0.025806   \n",
       "3904892  0.057306  0.417133  0.039897    0.000000  0.000000  0.279122   \n",
       "2809157  0.000000  0.000000  0.629264    0.000000  0.000000  0.027967   \n",
       "2807076  0.080663  0.038353  0.138880    0.019147  0.011558  0.048690   \n",
       "227884   0.304475  0.294645  0.000000    0.000000  0.000000  0.012297   \n",
       "1324912  0.015730  0.000000  0.000000    0.000000  0.000000  0.185277   \n",
       "5918792  0.005506  0.002135  0.005547    0.000000  0.001751  0.007695   \n",
       "3842428  0.000000  0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "279819   0.030443  0.018876  0.001013    0.036725  0.000000  0.015842   \n",
       "3058165  0.064279  0.000000  0.000000    0.009494  0.000000  0.004747   \n",
       "2591500  0.282501  0.043323  0.014995    0.000000  0.043323  0.025428   \n",
       "640113   0.072551  0.024160  0.345951    0.000000  0.000000  0.082048   \n",
       "5410862  0.074592  0.014797  0.479465    0.000000  0.007399  0.029506   \n",
       "3673582  0.059439  0.058418  0.000000    0.000000  0.003645  0.107653   \n",
       "1802236  0.000000  0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "\n",
       "            시즌스포츠      여성의류   인테리어/조명  속옷/양말/홈웨어    ...           음료  \\\n",
       "6382771  0.000000  0.018519  0.000000   0.685185    ...     0.000000   \n",
       "456508   0.000000  0.000000  0.000000   0.000000    ...     0.000000   \n",
       "5888892  0.016550  0.806235  0.000000   0.004064    ...     0.000000   \n",
       "3399944  0.000000  0.000000  0.000000   0.000000    ...     0.000000   \n",
       "5793121  0.251477  0.006970  0.000000   0.000000    ...     0.000000   \n",
       "840339   0.363636  0.000000  0.000000   0.000000    ...     0.000000   \n",
       "2161500  0.000000  0.425077  0.000000   0.027212    ...     0.000000   \n",
       "4257175  0.000000  0.000000  0.000000   0.009604    ...     0.019209   \n",
       "94099    0.001848  0.000000  0.000000   0.792910    ...     0.000000   \n",
       "2893690  0.000000  0.032503  0.000000   0.326097    ...     0.000000   \n",
       "845631   0.000000  0.000000  0.000000   0.000000    ...     0.000000   \n",
       "3911038  0.000000  0.000000  0.000000   0.616485    ...     0.000000   \n",
       "2630293  0.025205  0.283707  0.000000   0.391651    ...     0.000000   \n",
       "1195232  0.011310  0.179846  0.000000   0.173633    ...     0.009709   \n",
       "4281801  0.005297  0.009464  0.000000   0.029522    ...     0.000000   \n",
       "872046   0.009264  0.083355  0.000000   0.034278    ...     0.000000   \n",
       "4420720  0.055429  0.096529  0.000000   0.068490    ...     0.000000   \n",
       "1784391  0.647853  0.045154  0.000000   0.000000    ...     0.000000   \n",
       "6273632  0.035439  0.145729  0.000000   0.046443    ...     0.007336   \n",
       "780855   0.001503  0.020646  0.000000   0.044497    ...     0.005526   \n",
       "508      0.040600  0.040600  0.000000   0.041955    ...     0.000000   \n",
       "4947160  0.014378  0.100725  0.000000   0.042582    ...     0.015927   \n",
       "1075700  0.000000  0.000000  0.000000   0.000000    ...     0.000000   \n",
       "2811724  0.041304  0.092212  0.000000   0.078766    ...     0.009337   \n",
       "1891232  0.002923  0.494199  0.000000   0.157689    ...     0.000000   \n",
       "4798018  0.028590  0.137101  0.000000   0.180471    ...     0.003899   \n",
       "3758423  0.007231  0.038139  0.000000   0.109800    ...     0.000000   \n",
       "819226   0.000000  0.000000  0.000000   0.000000    ...     0.000000   \n",
       "6006194  0.000000  0.015460  0.000000   0.000000    ...     0.000000   \n",
       "3546518  0.006007  0.367204  0.000000   0.000000    ...     0.000000   \n",
       "...           ...       ...       ...        ...    ...          ...   \n",
       "6247353  0.000000  0.000000  0.000000   0.000000    ...     0.000000   \n",
       "5431483  0.007834  0.097413  0.005117   0.296460    ...     0.003411   \n",
       "5832211  0.030682  0.024584  0.000000   0.064508    ...     0.023517   \n",
       "1119542  0.000000  0.422144  0.000000   0.019520    ...     0.012306   \n",
       "5662235  0.002549  0.035646  0.000000   0.029686    ...     0.012340   \n",
       "2169344  0.000000  0.000000  0.000000   0.000000    ...     0.008931   \n",
       "5136367  0.000000  0.583333  0.000000   0.000000    ...     0.000000   \n",
       "2232509  0.137712  0.000000  0.000000   0.000000    ...     0.000000   \n",
       "3822519  0.000000  0.430009  0.000000   0.015200    ...     0.002696   \n",
       "6562567  0.000000  0.062059  0.000000   0.042988    ...     0.000000   \n",
       "2511277  0.012822  0.042426  0.042349   0.319080    ...     0.000000   \n",
       "2519443  0.118632  0.091760  0.000000   0.205510    ...     0.015891   \n",
       "5710923  0.000000  0.000000  0.000000   0.000000    ...     0.000000   \n",
       "5116194  0.028029  0.241589  0.000000   0.230374    ...     0.000000   \n",
       "65319    0.017406  0.048927  0.000000   0.117947    ...     0.020013   \n",
       "1010004  0.005161  0.333417  0.000000   0.000000    ...     0.000000   \n",
       "3904892  0.022170  0.102783  0.000000   0.022170    ...     0.000000   \n",
       "2809157  0.000000  0.000000  0.000000   0.027967    ...     0.000000   \n",
       "2807076  0.042328  0.200096  0.000000   0.038710    ...     0.011896   \n",
       "227884   0.000000  0.209220  0.000000   0.087646    ...     0.000000   \n",
       "1324912  0.000000  0.625902  0.000000   0.000000    ...     0.000000   \n",
       "5918792  0.000350  0.006060  0.945205   0.002696    ...     0.000000   \n",
       "3842428  0.000000  0.000000  0.000000   0.318182    ...     0.000000   \n",
       "279819   0.000591  0.016781  0.783928   0.025901    ...     0.001679   \n",
       "3058165  0.000000  0.055776  0.000000   0.000000    ...     0.000000   \n",
       "2591500  0.006874  0.530007  0.000000   0.027498    ...     0.000000   \n",
       "640113   0.021869  0.032658  0.000000   0.012080    ...     0.000000   \n",
       "5410862  0.022146  0.007399  0.000000   0.214588    ...     0.000000   \n",
       "3673582  0.000000  0.055838  0.010934   0.102157    ...     0.000000   \n",
       "1802236  0.000000  0.000000  0.000000   0.526786    ...     0.000000   \n",
       "\n",
       "         구기/필드스포츠   냉장/세탁가전      냉동식품      냉장식품     원예/애완       상품권     자동차용품  \\\n",
       "6382771  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "456508   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5888892  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3399944  0.116133  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5793121  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "840339   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2161500  0.000750  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4257175  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "94099    0.001848  0.000000  0.003695  0.000000  0.000000  0.000000  0.000000   \n",
       "2893690  0.000000  0.000000  0.000000  0.000000  0.010886  0.000000  0.000000   \n",
       "845631   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3911038  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2630293  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1195232  0.002474  0.000000  0.014175  0.000000  0.000000  0.002474  0.000000   \n",
       "4281801  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "872046   0.000000  0.000000  0.006054  0.001422  0.010340  0.000000  0.000000   \n",
       "4420720  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1784391  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6273632  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "780855   0.000000  0.000000  0.000000  0.001503  0.006300  0.000000  0.000000   \n",
       "508      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4947160  0.000000  0.007152  0.000000  0.000000  0.014551  0.000000  0.000000   \n",
       "1075700  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2811724  0.000000  0.000000  0.000000  0.000000  0.023777  0.000000  0.000000   \n",
       "1891232  0.007276  0.000000  0.000000  0.000000  0.010627  0.000000  0.000000   \n",
       "4798018  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3758423  0.005472  0.000000  0.004354  0.000000  0.000000  0.000000  0.000000   \n",
       "819226   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6006194  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3546518  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "6247353  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5431483  0.001706  0.000000  0.003411  0.000000  0.023632  0.000000  0.000000   \n",
       "5832211  0.000000  0.000000  0.014587  0.000000  0.000000  0.007294  0.000000   \n",
       "1119542  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5662235  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2169344  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5136367  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2232509  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3822519  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6562567  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2511277  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2519443  0.004729  0.000000  0.001086  0.000000  0.000000  0.000000  0.000000   \n",
       "5710923  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5116194  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "65319    0.013112  0.000000  0.000000  0.000000  0.304113  0.000000  0.000000   \n",
       "1010004  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3904892  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2809157  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2807076  0.002332  0.000000  0.000000  0.002332  0.000000  0.000000  0.009226   \n",
       "227884   0.010201  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1324912  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5918792  0.000000  0.000000  0.000000  0.000000  0.003602  0.000000  0.000000   \n",
       "3842428  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "279819   0.000000  0.001679  0.000000  0.001182  0.000000  0.000507  0.000000   \n",
       "3058165  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2591500  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "640113   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5410862  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3673582  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1802236  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "              축산물   영상/음향가전  \n",
       "6382771  0.000000  0.000000  \n",
       "456508   0.000000  0.000000  \n",
       "5888892  0.000000  0.000000  \n",
       "3399944  0.000000  0.000000  \n",
       "5793121  0.000000  0.000000  \n",
       "840339   0.000000  0.000000  \n",
       "2161500  0.000000  0.000000  \n",
       "4257175  0.000000  0.000000  \n",
       "94099    0.000000  0.000000  \n",
       "2893690  0.003577  0.000000  \n",
       "845631   0.000000  0.000000  \n",
       "3911038  0.000000  0.000000  \n",
       "2630293  0.000000  0.000000  \n",
       "1195232  0.000000  0.000000  \n",
       "4281801  0.000000  0.005297  \n",
       "872046   0.391964  0.000000  \n",
       "4420720  0.000000  0.000000  \n",
       "1784391  0.000000  0.000000  \n",
       "6273632  0.000000  0.000000  \n",
       "780855   0.006012  0.000000  \n",
       "508      0.000000  0.000000  \n",
       "4947160  0.000000  0.000000  \n",
       "1075700  0.000000  0.000000  \n",
       "2811724  0.000000  0.000000  \n",
       "1891232  0.000000  0.000000  \n",
       "4798018  0.000000  0.001950  \n",
       "3758423  0.003975  0.000000  \n",
       "819226   0.000000  0.000000  \n",
       "6006194  0.000000  0.000000  \n",
       "3546518  0.000000  0.000000  \n",
       "...           ...       ...  \n",
       "6247353  0.000000  0.000000  \n",
       "5431483  0.000000  0.005117  \n",
       "5832211  0.000000  0.000000  \n",
       "1119542  0.000000  0.000000  \n",
       "5662235  0.000000  0.000000  \n",
       "2169344  0.000000  0.000000  \n",
       "5136367  0.000000  0.000000  \n",
       "2232509  0.000000  0.000000  \n",
       "3822519  0.000000  0.000000  \n",
       "6562567  0.000000  0.000000  \n",
       "2511277  0.000000  0.000000  \n",
       "2519443  0.000000  0.000000  \n",
       "5710923  0.000000  0.000000  \n",
       "5116194  0.000000  0.000000  \n",
       "65319    0.000000  0.008741  \n",
       "1010004  0.000000  0.000000  \n",
       "3904892  0.000000  0.000000  \n",
       "2809157  0.000000  0.000000  \n",
       "2807076  0.000000  0.000000  \n",
       "227884   0.000000  0.000000  \n",
       "1324912  0.000000  0.000000  \n",
       "5918792  0.000000  0.000000  \n",
       "3842428  0.000000  0.000000  \n",
       "279819   0.000000  0.000000  \n",
       "3058165  0.000000  0.000000  \n",
       "2591500  0.000000  0.000000  \n",
       "640113   0.000000  0.000000  \n",
       "5410862  0.000000  0.000000  \n",
       "3673582  0.000000  0.000000  \n",
       "1802236  0.000000  0.000000  \n",
       "\n",
       "[8124 rows x 37 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Scaling 적용할 경우\n",
    "#20000명 sampling한 경우, cosine distance 쓴 경우, k = 5\n",
    "purchase_prediction(train_mat,test_mat, \"cosine\", 5, True, True)\n",
    "purchase_prediction(train_mat,test_mat, \"euclidean\", 5, True, True)\n",
    "purchase_prediction(train_mat,test_mat, \"correlation\", 5, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 검색선호지수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)10000명 sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: {:4.2f}% 10.11659141155544\n",
      "(5029, 37)\n",
      "(2477, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기 및 초기화\n",
    "Search_Count = pd.read_csv(\"C:/Users/lsh93/Desktop/Lpoint/data2/Search_CNT.csv\")\n",
    "Search_Count = Search_Count.rename(columns = {'Unnamed: 0':'CLNT_ID'})\n",
    "clustered_10000 = pd.read_csv(\"C:/Users/lsh93/Desktop/Lpoint/output2/clustered_10000.csv\", encoding = \"UTF-8\")\n",
    "clustered_10000 = clustered_10000.drop(['Unnamed: 0'], axis = 1)\n",
    "Search_Count = pd.merge(Search_Count, clustered_10000[['CLNT_ID']], how = 'inner', on ='CLNT_ID')\n",
    "row_names = Search_Count['CLNT_ID'].as_matrix()\n",
    "col_names = Search_Count.columns.values\n",
    "col_names = col_names[1:]\n",
    "PC = Search_Count.as_matrix()\n",
    "PC = PC[:,1:]\n",
    "Search_Count = pd.DataFrame(PC, columns = col_names, index = row_names)\n",
    "#sparsity구하기\n",
    "sparsity = float(len(PC.nonzero()[0]))\n",
    "sparsity /= (PC.shape[0] * PC.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.2f}%',format(sparsity))\n",
    "#test set과 training set으로 나누기\n",
    "PC_train, PC_test = train_test_split(Search_Count, test_size = 0.33, random_state = 50)\n",
    "print(PC_train.shape)\n",
    "print(PC_test.shape)\n",
    "PC_train = pd.DataFrame(PC_train)\n",
    "PC_test = pd.DataFrame(PC_test)\n",
    "#array 형태로 변환\n",
    "train_mat = PC_train.as_matrix()\n",
    "test_mat = PC_test.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)20000명 sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: {:4.2f}% 10.898478428826948\n",
      "(10265, 37)\n",
      "(5057, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기 및 초기화\n",
    "Search_Count = pd.read_csv(\"C:/Users/lsh93/Desktop/Lpoint/data2/Search_CNT.csv\")\n",
    "Search_Count = Search_Count.rename(columns = {'Unnamed: 0':'CLNT_ID'})\n",
    "clustered_10000 = pd.read_csv(\"C:/Users/lsh93/Desktop/Lpoint/output2/clustered_20000.csv\", encoding = \"UTF-8\")\n",
    "clustered_10000 = clustered_10000.drop(['Unnamed: 0'], axis = 1)\n",
    "Search_Count = pd.merge(Search_Count, clustered_10000[['CLNT_ID']], how = 'inner', on ='CLNT_ID')\n",
    "row_names = Search_Count['CLNT_ID'].as_matrix()\n",
    "col_names = Search_Count.columns.values\n",
    "col_names = col_names[1:]\n",
    "PC = Search_Count.as_matrix()\n",
    "PC = PC[:,1:]\n",
    "Search_Count = pd.DataFrame(PC, columns = col_names, index = row_names)\n",
    "#sparsity구하기\n",
    "sparsity = float(len(PC.nonzero()[0]))\n",
    "sparsity /= (PC.shape[0] * PC.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.2f}%',format(sparsity))\n",
    "#test set과 training set으로 나누기\n",
    "PC_train, PC_test = train_test_split(Search_Count, test_size = 0.33, random_state = 50)\n",
    "print(PC_train.shape)\n",
    "print(PC_test.shape)\n",
    "PC_train = pd.DataFrame(PC_train)\n",
    "PC_test = pd.DataFrame(PC_test)\n",
    "#array 형태로 변환\n",
    "train_mat = PC_train.as_matrix()\n",
    "test_mat = PC_test.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색선호지수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###파라메터 = k랑 코사인 \n",
    "def search_prediction(train_mat, test_mat, metric_, k, output = False, scaling = False):\n",
    "    if scaling == True:\n",
    "        train_mat = (train_mat.T/train_mat.sum(axis=1)).T\n",
    "        test_mat = (test_mat.T/test_mat.sum(axis=1)).T\n",
    "        \n",
    "    dist_out = 1 - pairwise_distances(train_mat, metric= metric_)\n",
    "\n",
    "    #without kmeans clustering\n",
    "    user_pred = dist_out.dot(train_mat)/np.array([np.abs(dist_out).sum(axis = 1)]).T\n",
    "    print('w/o kmeans, train:  ',get_mse(user_pred, train_mat))\n",
    "    print('w/o kmeans, test:  ',get_mse(user_pred, test_mat))\n",
    "\n",
    "    #with kmeans clustering\n",
    "    neigh = NearestNeighbors(k, metric_)\n",
    "    neigh.fit(train_mat)\n",
    "    top_k_distances, top_k_users = neigh.kneighbors(train_mat, return_distance = True)\n",
    "    user_pred_k = np.zeros(train_mat.shape)\n",
    "    \n",
    "    for i in range(PC_train.shape[0]):\n",
    "        user_pred_k[i,:] = top_k_distances[i].T.dot(train_mat[top_k_users][i]) / np.array([np.abs(top_k_distances[i].T).sum(axis = 0)]).T  \n",
    "    online_pref = pd.DataFrame(user_pred_k)\n",
    "    na_element_index = np.where(np.isnan(online_pref))\n",
    "    na_row_index = np.unique(na_element_index[0])\n",
    "    removed_CLNT_ID = PC_train.index.values[na_row_index]\n",
    "    existed_CLNT_ID = np.delete(PC_train.index.values,na_row_index)\n",
    "    online_pref2 = online_pref.dropna()\n",
    "    user_pred_k2 = online_pref2.as_matrix()\n",
    "    train_mat2 = train_mat\n",
    "    exist_idx = np.delete([range(online_pref.shape[0])],na_row_index)\n",
    "    train_mat2 = train_mat2[exist_idx,:]\n",
    "    print('w/ kmeans, train:  ',get_mse(user_pred_k2, train_mat2))\n",
    "    print('w/ kmeans, test:  ',get_mse(user_pred_k2, test_mat))\n",
    "\n",
    "    #kmeans 적용한 선호지수 matrix 생성\n",
    "    if output == True :\n",
    "        col_names = Search_Count.columns.values\n",
    "        row_names = existed_CLNT_ID\n",
    "        Online_Preference_Search = pd.DataFrame(user_pred_k2, columns = col_names, index = row_names)\n",
    "        return Online_Preference_Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10000명 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   4615.882115392347\n",
      "w/o kmeans, test:   924.2527845270545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   3011.175289814995\n",
      "w/ kmeans, test:   1360.5331990912446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#10000명 sampling한 경우, cosine distance 쓴 경우, k = 5\n",
    "ops = search_prediction(train_mat,test_mat, \"cosine\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   16327.345607006568\n",
      "w/o kmeans, test:   16043.406573066946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   3011.175289814995\n",
      "w/ kmeans, test:   1360.5331990912446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#10000명 sampling한 경우, euclidean distance 쓴 경우, k = 5\n",
    "ops = search_prediction(train_mat,test_mat, \"euclidean\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   4598.456219440562\n",
      "w/o kmeans, test:   957.5635999319992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   3011.175289814995\n",
      "w/ kmeans, test:   1360.5331990912446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#10000명 sampling한 경우, correlation 쓴 경우, k = 5\n",
    "ops = search_prediction(train_mat,test_mat, \"correlation\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   0.03602239096595326\n",
      "w/o kmeans, test:   0.12796806259553326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.003323832338825208\n",
      "w/ kmeans, test:   0.14392997683927655\n",
      "w/o kmeans, train:   0.07715384905738594\n",
      "w/o kmeans, test:   0.1634055741779153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.003323832338825208\n",
      "w/ kmeans, test:   0.14392997683927655\n",
      "w/o kmeans, train:   0.042150909706843716\n",
      "w/o kmeans, test:   0.13901195661203594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.003323832338825208\n",
      "w/ kmeans, test:   0.14392997683927655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "##Scaling 적용할 경우\n",
    "#10000명 sampling한 경우, cosine distance 쓴 경우, k = 5\n",
    "ops = search_prediction(train_mat,test_mat, \"cosine\", 5, True, True)\n",
    "ops = search_prediction(train_mat,test_mat, \"euclidean\", 5, True, True)\n",
    "ops = search_prediction(train_mat,test_mat, \"correlation\", 5, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20000명 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   4615.882115392347\n",
      "w/o kmeans, test:   924.2527845270545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   3011.175289814995\n",
      "w/ kmeans, test:   1360.5331990912446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#20000명 sampling한 경우, cosine distance 쓴 경우, k = 5\n",
    "ops = search_prediction(train_mat,test_mat, \"cosine\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   16327.345607006568\n",
      "w/o kmeans, test:   16043.406573066946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   3011.175289814995\n",
      "w/ kmeans, test:   1360.5331990912446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#20000명 sampling한 경우, euclidean distance 쓴 경우, k = 5\n",
    "ops = search_prediction(train_mat,test_mat, \"euclidean\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   4598.456219440562\n",
      "w/o kmeans, test:   957.5635999319992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   3011.175289814995\n",
      "w/ kmeans, test:   1360.5331990912446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#20000명 sampling한 경우, correlation 쓴 경우, k = 5\n",
    "ops = search_prediction(train_mat,test_mat, \"correlation\", 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o kmeans, train:   0.03581917196583815\n",
      "w/o kmeans, test:   0.11192931135624402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.002683239924003692\n",
      "w/ kmeans, test:   0.1290034655472081\n",
      "w/o kmeans, train:   0.07827259425732647\n",
      "w/o kmeans, test:   0.1387689249691853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.002683239924003692\n",
      "w/ kmeans, test:   0.1290034655472081\n",
      "w/o kmeans, train:   0.044407876584194365\n",
      "w/o kmeans, test:   0.12250626694137244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ kmeans, train:   0.002683239924003692\n",
      "w/ kmeans, test:   0.1290034655472081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsh93\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "##Scaling 적용할 경우\n",
    "#20000명 sampling한 경우, cosine distance 쓴 경우, k = 5\n",
    "ops = search_prediction(train_mat,test_mat, \"cosine\", 5, True, True)\n",
    "ops = search_prediction(train_mat,test_mat, \"euclidean\", 5, True, True)\n",
    "ops = search_prediction(train_mat,test_mat, \"correlation\", 5, True, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
